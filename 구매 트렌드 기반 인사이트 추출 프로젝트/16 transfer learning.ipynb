{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRTa3Ee15WsJ"
   },
   "source": [
    "# 사전 학습된 ConvNet을 이용한 전이 학습\n",
    "# tensorflowr -> pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2X4KyhORdSeO"
   },
   "source": [
    "이 튜토리얼에서는 사전 훈련된 네트워크에서 전이 학습을 사용하여 고양이와 개의 이미지를 분류하는 방법을 배우게 됩니다.\n",
    "\n",
    "사전 훈련된 모델은 이전에 대규모 데이터셋에서 훈련된 저장된 네트워크로, 일반적으로 대규모 이미지 분류 작업에서 훈련된 것입니다. 사전 훈련된 모델을 그대로 사용하거나 전이 학습을 사용하여 이 모델을 주어진 작업으로 사용자 정의하세요.\n",
    "\n",
    "이미지 분류를 위한 전이 학습을 직관적인 시각에서 바라보면 모델이 충분히 크고 일반적인 데이터 집합에서 훈련된다면, 이 모델은 사실상 시각 세계의 일반적인 모델로서 기능할 것이라는 점입니다. 그런 다음 대규모 데이터셋에서 대규모 모델을 교육하여 처음부터 시작할 필요 없이 이러한 학습된 특징 맵을 활용할 수 있습니다.\n",
    "\n",
    "이번 notebook에서는 사전 훈련된 모델을 사용자 정의하는 두 가지 방법을 시도 해보겠습니다.:\n",
    "\n",
    "1. 특성 추출: 새 샘플에서 의미 있는 특성을 추출하기 위해 이전 네트워크에서 학습한 표현을 사용합니다. 사전 훈련된 모델 위에 처음부터 훈련할 새 분류자를 추가하기만 하면 이전에 데이터세트로 학습한 특성 맵의 용도를 재사용할 수 있습니다.\n",
    "\n",
    "전체 모델을 재훈련시킬 필요는 없습니다. 기본 컨볼루션 네트워크에는 그림 분류에 일반적으로 유용한 기능이 이미 포함되어 있습니다. 그러나 사전 훈련된 모델의 최종 분류 부분은 기존의 분류 작업에 따라 다르며 이후에 모델이 훈련된 클래스 집합에 따라 다릅니다.\n",
    "\n",
    "1. 미세 조정: 고정된 기본 모델의 일부 최상위 층을 고정 해제하고 새로 추가 된 분류기 층과 기본 모델의 마지막 층을 함께 훈련시킵니다. 이를 통해 기본 모델에서 고차원 특징 표현을 \"미세 조정\"하여 특정 작업에 보다 관련성이 있도록 할 수 있습니다.\n",
    "\n",
    "일반적인 기계 학습 일련의 과정을 진행합니다.\n",
    "\n",
    "1. 데이터 검사 및 이해\n",
    "2. 입력 파이프 라인 빌드(이 경우 Keras ImageDataGenerator를 사용)\n",
    "3. 모델 작성\n",
    "    - 사전 훈련된 기본 모델(또한 사전 훈련된 가중치)에 적재\n",
    "    - 분류 레이어를 맨 위에 쌓기\n",
    "4. 모델 훈련\n",
    "5. 모델 평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T01:36:06.793290Z",
     "iopub.status.busy": "2022-12-15T01:36:06.792749Z",
     "iopub.status.idle": "2022-12-15T01:36:09.288472Z",
     "shell.execute_reply": "2022-12-15T01:36:09.287701Z"
    },
    "id": "TqOt6Sv7AsMi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v77rlkCKW0IJ"
   },
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GoKGm1duzgk"
   },
   "source": [
    "### 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHP9qMJxt2oz"
   },
   "source": [
    "이 튜토리얼에서는 수천 개의 고양이와 개의 이미지가 포함된 데이터세트를 사용합니다. 이미지가 포함된 zip 파일을 다운로드하여 추출은 다음 `tf.keras.utils.image_dataset_from_directory` 유틸리티를 사용하여 훈련 및 검증을 위한 `tf.data.Dataset`를 생성합니다. 이 [튜토리얼](https://www.tensorflow.org/tutorials/load_data/images)에서 이미지 로드에 대해 자세히 알아볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T01:36:09.293328Z",
     "iopub.status.busy": "2022-12-15T01:36:09.292537Z",
     "iopub.status.idle": "2022-12-15T01:36:14.437579Z",
     "shell.execute_reply": "2022-12-15T01:36:14.436810Z"
    },
    "id": "ro4oYaEmxe4r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Dataset downloaded and extracted.\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터셋 다운로드 및 압축 해제 (이미 다운로드된 경우 건너뜁니다)\n",
    "url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "zip_filename = 'cats_and_dogs_filtered.zip'\n",
    "if not os.path.exists('cats_and_dogs_filtered'):\n",
    "    print(\"Downloading dataset...\")\n",
    "    urllib.request.urlretrieve(url, zip_filename)\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    print(\"Dataset downloaded and extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T01:36:14.442409Z",
     "iopub.status.busy": "2022-12-15T01:36:14.441690Z",
     "iopub.status.idle": "2022-12-15T01:36:14.507573Z",
     "shell.execute_reply": "2022-12-15T01:36:14.506848Z"
    },
    "id": "cAvtLwi7_J__"
   },
   "outputs": [],
   "source": [
    "# 2. 경로 설정\n",
    "BASE_DIR = os.path.join(os.getcwd(), 'cats_and_dogs_filtered')\n",
    "train_dir = os.path.join(BASE_DIR, 'train')\n",
    "validation_dir = os.path.join(BASE_DIR, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 하이퍼파라미터 설정\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)  # (height, width)\n",
    "base_learning_rate = 0.0001\n",
    "initial_epochs = 10\n",
    "fine_tune_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 데이터 전처리 및 데이터 증강\n",
    "# TF 코드에서는 RandomFlip, RandomRotation을 별도 레이어로 사용합니다.\n",
    "# 여기서는 transforms를 이용하여 이미지 증강 및 전처리 수행합니다.\n",
    "# MobileNetV2의 TF preprocess_input는 [0,255] -> [-1,1] 변환을 수행하므로,\n",
    "# ToTensor() 후 Normalize(mean=0.5, std=0.5)로 동일 효과를 줍니다.\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # tf.keras.layers.RandomRotation(0.2)는 약 ±72도 회전 효과를 줍니다.\n",
    "    transforms.RandomRotation(72),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transfer_learning.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "supernova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
