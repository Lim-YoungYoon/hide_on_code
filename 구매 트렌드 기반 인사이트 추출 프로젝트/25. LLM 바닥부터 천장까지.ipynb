{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 과정 요약  \n",
    "LLM 기반 AI 에이전트를 개발할 때 핵심 요소는 LLM 자체입니다. 대부분의 경우, 기초부터 새로운 LLM을 구축하기보다는 공개된 모델을 가져와 특정 용도에 맞게 조정하여 사용하는 방식이 일반적입니다. 하지만 최근에는 LLM을 처음부터 개발하는 기술적 장벽이 점차 낮아지고 있어, 각 기업이 자체적으로 최적화된 LLM을 구축하는 사례가 증가할 가능성이 높습니다.  \n",
    "\n",
    "## LLM 개발의 기본 과정  \n",
    "LLM을 구축하는 과정은 크게 다음과 같은 단계를 거칩니다.  \n",
    "\n",
    "1. **사전훈련(Pretraining)**: 일반적인 언어 이해 및 생성 능력을 학습  \n",
    "2. **미세조정(Fine-tuning)**: 특정 업무나 도메인에 맞게 추가 학습  \n",
    "\n",
    "이 과정에 더해, **데이터베이스 및 인터넷 검색 기능**을 통합하면 모델의 정보 범위와 정확도를 더욱 향상시킬 수 있습니다. 또한, 인간이 논리적 사고를 거듭하며 더 깊이 있는 결론을 도출하는 것처럼, LLM도 **내부적으로 질의를 반복하여 최적의 답을 찾는 방식**으로 개선할 수 있습니다.  \n",
    "\n",
    "이번 과정에서는 LLM의 기본 원리를 이해하기 위해 **사전훈련 과정을 처음부터 직접 수행**해 보겠습니다. 훈련 절차는 일반적인 머신러닝 방법론을 따르며, 다음과 같은 흐름으로 진행됩니다.  \n",
    "\n",
    "## 훈련 과정 개요  \n",
    "1. **훈련 데이터 준비**  \n",
    "   - 사용할 텍스트 데이터를 읽어 정리한 후, `cleaned_` 접두사를 붙여 가공된 파일로 저장합니다.  \n",
    "   - 예시: `alice.txt` → `cleaned_alice.txt`  \n",
    "\n",
    "2. **데이터 로더 정의**  \n",
    "   - 모델이 효율적으로 학습할 수 있도록 데이터를 배치 형태로 로드하는 과정  \n",
    "\n",
    "3. **모델 정의**  \n",
    "   - 사전훈련을 위한 LLM 아키텍처 설정  \n",
    "\n",
    "4. **훈련 실행**  \n",
    "   - 정의된 모델을 기반으로 데이터 학습 진행  \n",
    "\n",
    "5. **결과 확인**  \n",
    "   - 모델의 성능 및 학습 진행 상황을 평가  \n",
    "\n",
    "예제 데이터셋으로는 **캐글에서 제공하는 해리포터 책(Harry Potter Books)** 또는 **앨리스 책(alice.txt)** 등을 활용할 수 있습니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_02 Harry Potter and the Chamber of Secrets.txt 488771 characters\n"
     ]
    }
   ],
   "source": [
    "import re  # 정규 표현식 모듈을 불러옴\n",
    "\n",
    "def clean_text(filename):\n",
    "    \"\"\"\n",
    "    주어진 텍스트 파일을 불러와 불필요한 줄바꿈과 공백을 제거한 후,\n",
    "    새로운 파일로 저장하는 함수.\n",
    "    \n",
    "    :param filename: 원본 텍스트 파일의 이름 (문자열)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 파일을 읽기 모드('r')로 열고 UTF-8 인코딩을 사용하여 내용을 가져옴\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        book_text = file.read()\n",
    "\n",
    "    # 여러 개의 연속된 줄바꿈(\\n)을 공백(' ')으로 변경\n",
    "    cleaned_text = re.sub(r'\\n+', ' ', book_text)\n",
    "\n",
    "    # 여러 개의 연속된 공백(\\s)을 하나의 공백(' ')으로 변경\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "\n",
    "    # 정리된 텍스트의 총 문자 수 출력\n",
    "    print(\"cleaned_\" + filename, len(cleaned_text), \"characters\")\n",
    "\n",
    "    # 정리된 텍스트를 새로운 파일(\"cleaned_\" + 원본파일명)로 저장\n",
    "    with open(\"cleaned_\" + filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "# 정리할 파일 목록을 리스트로 정의\n",
    "filenames_list = [\"02 Harry Potter and the Chamber of Secrets.txt\"]\n",
    "\n",
    "# 리스트에 있는 각 파일에 대해 clean_text 함수를 호출하여 처리\n",
    "for filename in filenames_list:\n",
    "    clean_text(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화\n",
    "UTF-8 BPE(Bype Pair Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자수: 26 토큰수: 6\n",
      "[18308, 14179, 373, 257, 18731, 13]\n",
      "Harry Potter was a wizard.\n",
      "18308\t -> Harry\n",
      "14179\t ->  Potter\n",
      "373\t ->  was\n",
      "257\t ->  a\n",
      "18731\t ->  wizard\n",
      "13\t -> .\n"
     ]
    }
   ],
   "source": [
    "import tiktoken  # tiktoken 라이브러리를 불러옴 (설치 필요: pip install tiktoken)\n",
    "\n",
    "# GPT-2 모델에서 사용하는 인코딩 방식 가져오기\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# 입력할 텍스트 정의\n",
    "text = \"Harry Potter was a wizard.\"\n",
    "\n",
    "# 텍스트를 토큰으로 변환 (인코딩)\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "# 글자 수와 토큰 수 출력\n",
    "print(\"글자수:\", len(text), \"토큰수:\", len(tokens))\n",
    "\n",
    "# 변환된 토큰 리스트 출력\n",
    "print(tokens)\n",
    "\n",
    "# 토큰을 다시 텍스트로 변환 (디코딩)하여 출력\n",
    "print(tokenizer.decode(tokens))\n",
    "\n",
    "# 개별 토큰과 해당 토큰이 의미하는 문자열 출력\n",
    "for t in tokens:\n",
    "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer # pip install transformers\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 사용\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 사용\n",
    "\n",
    "# print(\"Vocab size :\", len(tokenizer))\n",
    "\n",
    "# text = \"한국어 테스트\"\n",
    "\n",
    "# tokens = tokenizer.encode(text)\n",
    "\n",
    "# print(len(text), len(tokens))\n",
    "# print(tokens)\n",
    "# print(tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H -> [39] -> H\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "r -> [81] -> r\n",
      "y -> [88] -> y\n",
      "  -> [220] ->  \n",
      "P -> [47] -> P\n",
      "o -> [78] -> o\n",
      "t -> [83] -> t\n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "r -> [81] -> r\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "a -> [64] -> a\n",
      "s -> [82] -> s\n",
      "  -> [220] ->  \n",
      "a -> [64] -> a\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "i -> [72] -> i\n",
      "z -> [89] -> z\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "d -> [67] -> d\n",
      ". -> [13] -> .\n"
     ]
    }
   ],
   "source": [
    "for char in text:\n",
    "    token_ids = tokenizer.encode(char)     # 한 글자씩 인코딩(토큰화)\n",
    "    decoded = tokenizer.decode(token_ids)  # 한 글자씩 디코딩\n",
    "    print(f\"{char} -> {token_ids} -> {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터로더(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tokens in txt: 130520\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    주어진 텍스트를 토큰화한 후, 일정한 길이(max_length)로 분할하여 학습용 데이터셋을 생성하는 클래스.\n",
    "    \n",
    "    - 입력 시퀀스(input_ids)와 정답 시퀀스(target_ids)를 생성.\n",
    "    - stride 간격으로 데이터 슬라이딩 윈도우 방식으로 분할.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, txt, max_length, stride):\n",
    "        self.input_ids = []  # 입력 데이터 리스트\n",
    "        self.target_ids = []  # 정답 데이터 리스트\n",
    "\n",
    "        # 텍스트를 토큰화하여 토큰 ID 리스트 생성\n",
    "        # \"<|endoftext|>\" 토큰을 포함하려면 주석 해제\n",
    "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        print(\"# of tokens in txt:\", len(token_ids))  # 전체 토큰 개수 출력\n",
    "\n",
    "        # 슬라이딩 윈도우 방식으로 데이터 분할\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]  # 입력 데이터 (max_length 크기)\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]  # 정답 데이터 (다음 토큰)\n",
    "\n",
    "            # 텐서로 변환하여 리스트에 저장\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" 데이터셋의 총 샘플 개수 반환 \"\"\"\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" 특정 인덱스의 데이터 반환 \"\"\"\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "# 정리된 텍스트 파일을 불러오기\n",
    "with open(\"cleaned_02 Harry Potter and the Chamber of Secrets.txt\", 'r', encoding='utf-8-sig') as file:\n",
    "    txt = file.read()\n",
    "\n",
    "# 데이터셋 생성 (max_length=32, stride=4)\n",
    "dataset = MyDataset(txt, max_length=32, stride=4)\n",
    "\n",
    "# DataLoader 생성 (배치 크기 128, 셔플 적용, 마지막 배치 버림)\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "# 주의: test 및 valid 데이터셋 분할은 생략됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 시퀀스:\n",
      " inside it. “Remember Millicent Bulstrode wrestling with me at the Dueling Club? She left this on my robes when she was trying to str\n",
      "\n",
      "정답 시퀀스 (다음 토큰):\n",
      " it. “Remember Millicent Bulstrode wrestling with me at the Dueling Club? She left this on my robes when she was trying to strangle\n"
     ]
    }
   ],
   "source": [
    "# DataLoader의 iterator 생성\n",
    "dataiter = iter(train_loader)\n",
    "\n",
    "# 첫 번째 배치 데이터 가져오기\n",
    "x, y = next(dataiter)\n",
    "\n",
    "# 첫 번째 샘플을 토큰에서 텍스트로 변환하여 출력\n",
    "print(\"입력 시퀀스:\")\n",
    "print(tokenizer.decode(x[0].tolist()))  # 첫 번째 입력 데이터 디코딩\n",
    "\n",
    "print(\"\\n정답 시퀀스 (다음 토큰):\")\n",
    "print(tokenizer.decode(y[0].tolist()))  # 첫 번째 정답 데이터 디코딩\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴럴네트워크 모델 정의\n",
    "\"Build a Large Language Model (From Scratch)\"에서 제공하는 예제 코드를 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 정의할 때 사용하는 하이퍼파라미터 및 상수\n",
    "\n",
    "VOCAB_SIZE = tokenizer.n_vocab  # Tiktoken 기반의 어휘 크기 (GPT-2: 50257개 토큰)\n",
    "# VOCAB_SIZE = len(tokenizer)  # AutoTokenizer 사용 시 (주석 처리됨)\n",
    "\n",
    "CONTEXT_LENGTH = 128  # 컨텍스트 길이 (기본값: 1024에서 줄임, 메모리 절약 목적)\n",
    "EMB_DIM = 768  # 임베딩 차원 (GPT-2 Small과 동일)\n",
    "NUM_HEADS = 12  # 어텐션 헤드 개수 (GPT-2 Small 기준)\n",
    "NUM_LAYERS = 12  # Transformer 레이어 개수\n",
    "DROP_RATE = 0.1  # 드롭아웃 비율 (과적합 방지용)\n",
    "QKV_BIAS = False  # Query-Key-Value (QKV) 연산에서 bias 사용 여부 (기본적으로 False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max token ID = 50255\n",
      "Min token ID = 0\n",
      "VOCAB_SIZE = 50257\n"
     ]
    }
   ],
   "source": [
    "# 텍스트를 토큰화하여 토큰 ID 리스트 생성\n",
    "token_ids = tokenizer.encode(txt)\n",
    "\n",
    "# 토큰 ID의 최댓값과 최솟값 출력\n",
    "print(f\"Max token ID = {max(token_ids)}\")  # 사용된 토큰 중 가장 큰 ID\n",
    "print(f\"Min token ID = {min(token_ids)}\")  # 사용된 토큰 중 가장 작은 ID\n",
    "\n",
    "# 설정한 어휘 사전 크기 출력\n",
    "print(f\"VOCAB_SIZE = {VOCAB_SIZE}\")  # 토크나이저의 전체 어휘 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // NUM_HEADS  # 각 헤드의 차원 크기\n",
    "\n",
    "        # Query, Key, Value 프로젝션 레이어 정의 (bias 사용 여부는 QKV_BIAS 값에 따라 결정)\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "\n",
    "        # 최종 출력 프로젝션 레이어\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(DROP_RATE)  # 드롭아웃 추가\n",
    "\n",
    "        # Causal Mask (미래 정보를 참조하지 못하도록 상삼각행렬을 만듦)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape  # 배치 크기, 토큰 개수, 입력 차원\n",
    "\n",
    "        # Query, Key, Value 생성\n",
    "        keys = self.W_key(x)  \n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # (b, num_tokens, d_out) -> (b, num_tokens, NUM_HEADS, head_dim)\n",
    "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "\n",
    "        # 차원 변환: (b, num_tokens, NUM_HEADS, head_dim) → (b, NUM_HEADS, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # 어텐션 스코어 계산 (쿼리 @ 키의 전치 연산)\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # (b, NUM_HEADS, num_tokens, num_tokens)\n",
    "\n",
    "        # Causal Mask 적용 (미래 정보를 참조하지 않도록 설정)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        # 소프트맥스 및 드롭아웃 적용 후 가중합 수행\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # 값 벡터를 어텐션 가중치로 가중합한 후 차원 변환\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "\n",
    "        # 최종 출력\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" Layer Normalization (PyTorch 기본 LayerNorm 대신 직접 구현) \"\"\"\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))  # 학습 가능한 스케일\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))  # 학습 가능한 시프트\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    \"\"\" 활성화 함수 GELU (PyTorch 기본 제공되지 않는 버전) \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" Position-wise FeedForward Network \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(EMB_DIM, 4 * EMB_DIM),  # 확장된 차원\n",
    "            GELU(),  # 활성화 함수\n",
    "            nn.Linear(4 * EMB_DIM, EMB_DIM),  # 다시 원래 차원으로 축소\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\" Transformer Block (MultiHeadAttention + FeedForward + LayerNorm) \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=EMB_DIM,\n",
    "            d_out=EMB_DIM)\n",
    "    \n",
    "        self.ff = FeedForward()\n",
    "        self.norm1 = LayerNorm(EMB_DIM)\n",
    "        self.norm2 = LayerNorm(EMB_DIM)\n",
    "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 어텐션 블록 + Residual Connection\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        # FeedForward 블록 + Residual Connection\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    \"\"\" GPT 모델 정의 (Embedding + Transformer Blocks + Output Projection) \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)  # 토큰 임베딩\n",
    "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)  # 위치 임베딩\n",
    "        self.drop_emb = nn.Dropout(DROP_RATE)  # 드롭아웃\n",
    "\n",
    "        # 여러 개의 Transformer Block을 쌓은 모델\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock() for _ in range(NUM_LAYERS)]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(EMB_DIM)  # 마지막 LayerNorm\n",
    "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)  # 출력 레이어\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)  # 토큰 임베딩\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))  # 위치 임베딩 추가\n",
    "        x = tok_embeds + pos_embeds  # [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)  # Transformer 블록 통과\n",
    "        x = self.final_norm(x)  # 최종 LayerNorm\n",
    "        logits = self.out_head(x)  # 출력 로짓 계산\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU가 사용 가능한 경우 CUDA, 그렇지 않으면 CPU 선택\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"  # 강제로 CPU에서 실행하려면 이 줄의 주석을 해제\n",
    "\n",
    "print(f\"Using device: {device}\")  # 사용 중인 디바이스 출력\n",
    "\n",
    "# 랜덤 시드 설정 (재현성 보장)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# GPT 모델 인스턴스 생성 및 디바이스에 로드\n",
    "model = GPTModel().to(device)\n",
    "\n",
    "# AdamW 옵티마이저 설정\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),  # 모델의 학습 가능한 파라미터들\n",
    "    lr=0.0004,           # 학습률\n",
    "    weight_decay=0.1     # L2 정규화 계수 (가중치 감쇠)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens seen: 4096\n",
      "Epoch: 1, Loss: 4.398635850177975\n",
      "Epoch: 2, Loss: 2.2249906860937285\n",
      "Epoch: 3, Loss: 0.7975240455368372\n",
      "Tokens seen: 4100096\n",
      "Epoch: 4, Loss: 0.3918201016394172\n",
      "Epoch: 5, Loss: 0.3031856160698913\n",
      "Epoch: 6, Loss: 0.27067329212436525\n",
      "Epoch: 7, Loss: 0.2539949018185533\n",
      "Tokens seen: 8196096\n",
      "Epoch: 8, Loss: 0.24399263581891698\n",
      "Epoch: 9, Loss: 0.23760943930214784\n",
      "Epoch: 10, Loss: 0.23132647808611861\n",
      "Epoch: 11, Loss: 0.22604782591889225\n",
      "Tokens seen: 12292096\n",
      "Epoch: 12, Loss: 0.22180081563671744\n",
      "Epoch: 13, Loss: 0.21754667209827994\n",
      "Epoch: 14, Loss: 0.21513622793860324\n",
      "Epoch: 15, Loss: 0.21269897617927686\n",
      "Tokens seen: 16388096\n",
      "Epoch: 16, Loss: 0.21014627949224682\n",
      "Epoch: 17, Loss: 0.20854536842877472\n",
      "Epoch: 18, Loss: 0.20549855375383783\n",
      "Epoch: 19, Loss: 0.20375896468171922\n",
      "Tokens seen: 20484096\n",
      "Epoch: 20, Loss: 0.20105006809779039\n"
     ]
    }
   ],
   "source": [
    "tokens_seen, global_step = 0, -1  # 학습 진행 상태 추적 변수\n",
    "\n",
    "losses = []  # 에포크별 손실 값을 저장할 리스트\n",
    "\n",
    "for epoch in range(20):  # 최대 20 에포크 동안 학습 진행\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    \n",
    "    epoch_loss = 0  # 현재 에포크에서의 총 손실 값 초기화\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad()  # 이전 배치에서 계산된 그래디언트 초기화\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)  # 데이터를 GPU 또는 CPU로 이동\n",
    "\n",
    "        logits = model(input_batch)  # 모델이 예측한 로짓(logits) 출력\n",
    "        loss = torch.nn.functional.cross_entropy(\n",
    "            logits.flatten(0, 1),  # 출력을 (batch_size * sequence_length, vocab_size) 형태로 변경\n",
    "            target_batch.flatten()  # 정답을 (batch_size * sequence_length,) 형태로 변경\n",
    "        )\n",
    "        epoch_loss += loss.item()  # 에포크 손실에 현재 배치 손실을 추가\n",
    "\n",
    "        loss.backward()  # 손실을 기반으로 그래디언트(기울기) 계산\n",
    "        optimizer.step()  # 옵티마이저를 사용하여 모델의 가중치 업데이트\n",
    "\n",
    "        tokens_seen += input_batch.numel()  # 현재까지 처리한 총 토큰 개수 업데이트\n",
    "        global_step += 1  # 전역 스텝 증가\n",
    "\n",
    "        if global_step % 1000 == 0:  # 매 1000 스텝마다 진행 상황 출력\n",
    "            print(f\"Tokens seen: {tokens_seen}\")\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)  # 에포크의 평균 손실 계산\n",
    "    losses.append(avg_loss)  # 손실 기록\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
    "\n",
    "    # 현재 에포크의 모델 가중치를 저장 (파일명: model_001.pth, model_002.pth, ...)\n",
    "    torch.save(model.state_dict(), \"model_\" + str(epoch + 1).zfill(3) + \".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 손실 그래프 그리기\n",
    "plt.plot(losses, marker='o', linestyle='-')  # 손실 값 플로팅 (마커 추가)\n",
    "plt.xlabel('Epoch')  # X축 라벨 (에포크)\n",
    "plt.ylabel('Loss')  # Y축 라벨 (손실 값)\n",
    "plt.title('Training Loss Over Epochs')  # 그래프 제목\n",
    "plt.grid(True)  # 격자 추가 (가독성 향상)\n",
    "plt.show()  # 그래프 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(128, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일로 저장했던 네트워크의 가중치들 읽어들이기\n",
    "model.load_state_dict(torch.load(\"model_020.pth\", map_location=device))  # 저장된 모델 가중치 로드\n",
    "\n",
    "# 모델을 평가 모드로 설정 (dropout 등 비활성화)\n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.75\t 973\t  used\n",
      "11.14\t 257\t  a\n",
      "10.98\t 1464\t  always\n",
      "10.45\t 284\t  to\n",
      "9.99\t 1908\t  sent\n",
      "9.97\t 635\t  also\n",
      "9.67\t 991\t  still\n",
      "9.13\t 4978\t  caught\n",
      "9.01\t 2982\t  heard\n",
      "8.82\t 373\t  was\n",
      " used\n"
     ]
    }
   ],
   "source": [
    "idx = tokenizer.encode(\"Dobby is\")  # 입력 문자열을 토큰 ID 리스트로 변환\n",
    "idx = torch.tensor(idx).unsqueeze(0).to(device)  # 배치 차원 추가 후 GPU/CPU로 이동\n",
    "\n",
    "with torch.no_grad():  # 그라디언트 계산 비활성화 (추론 모드)\n",
    "    logits = model(idx)\n",
    "\n",
    "logits = logits[:, -1, :]  # 마지막 토큰에 대한 예측 로짓(logits) 가져오기\n",
    "\n",
    "# 가장 확률이 높은 단어 10개 출력\n",
    "top_logits, top_indices = torch.topk(logits, 10)  \n",
    "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
    "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")  # 확률과 함께 디코딩된 단어 출력\n",
    "\n",
    "# 가장 확률이 높은 단어 출력 (탑-1 예측)\n",
    "idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # 확률이 가장 높은 인덱스 선택\n",
    "flat = idx_next.squeeze(0)  # 배치 차원 제거 (torch.Size([1]) → torch.Size([]))\n",
    "out = tokenizer.decode(flat.tolist())  # 토큰 ID를 텍스트로 변환\n",
    "print(out)  # 예측된 다음 단어 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # 컨텍스트 크기만큼의 최근 토큰을 가져옴\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)  # 모델을 사용하여 다음 토큰의 확률 분포 예측\n",
    "        logits = logits[:, -1, :]  # 마지막 토큰의 예측 로짓 가져오기\n",
    "\n",
    "        # Top-k 샘플링 적용\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)  # 상위 k개의 토큰 선택\n",
    "            min_val = top_logits[:, -1]  # k번째로 확률이 높은 값\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # 온도 기반 확률 샘플링 적용\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature  # 온도를 적용하여 확률 분포 조정\n",
    "            probs = torch.softmax(logits, dim=-1)  # 확률 분포 계산\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # 확률에 따라 다음 토큰 샘플링\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # 가장 확률이 높은 토큰 선택\n",
    "\n",
    "        # 종료 토큰이 나오면 중단\n",
    "        if eos_id is not None and idx_next.item() == eos_id:\n",
    "            break\n",
    "\n",
    "        # 새로운 토큰을 기존 시퀀스에 추가\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : dobby’s lip trembled and Harry was seized by a sudden suspicion. “It was you!” he said slowly. “You stopped quickly gone his friends’s ugly baby popped’s the real you, dear!\n",
      "1 : dobby, but he was supposed to be in the greenhouse, he opened the door and slid inside. Professor Sprout was standing behind a trestle bench in the center of the center of the center of the center to the center of the center to the\n",
      "2 : dobby’s lip trembled and Harry was seized by a sudden suspicion. “It was you!” he said slowly. “You stopped quickly, Myrtle shouted, what did you, but it’s the way — �\n",
      "3 : dobby. “I know!” said Lockhart. “Six solid months at the top of the best-seller list! Broke all records,’s Who wanted!’ll be a lovely kind of all records!�\n",
      "4 : dobby, but it was only Fang’s nose. “What d’you reckon?” Harry said to Ron, whose eyes he could just because he could see him tightly around to make sure they were looking at once again. �\n",
      "5 : dobby’s lip trembled and Harry was seized by a sudden suspicion. “It was you!” he said slowly. “You stopped quickly gone his friends only a bit of the way to see you, dear old Dumbledore, Myr\n",
      "6 : dobby would be able to revive those people who have been Petrified. I need hardly remind you all that one of them may well be able to tell us who, or anything that you, or Mandrakes, won’ll tell us who,\n",
      "7 : dobby’s lip trembled and Harry was seized by a sudden suspicion. “It was you!” he said slowly. “You stopped quickly, dear friends only wanted to disappoint down there, as the best friends only wanted to clear\n",
      "8 : dobby. “So. Your mother died to save you. Yes, that’s a powerful countercharm. I can see now…there is nothing Slytherin’s go down here, however, however, however, just let\n",
      "9 : dobby. “We’re being flattened. Fred, George, where were you when that Bludger stopped Angelina scoring?” “We were electric if they reached for a bit of it was another word, Severus, Lockhart\n"
     ]
    }
   ],
   "source": [
    "start_context = input(\"Start context: \")  # 사용자 입력 받기\n",
    "\n",
    "# 입력 텍스트를 토큰화\n",
    "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})  # 필요 시 special token 허용\n",
    "idx = tokenizer.encode(start_context)\n",
    "idx = torch.tensor(idx).unsqueeze(0)  # 배치 차원 추가 (shape: [1, sequence_length])\n",
    "\n",
    "# 모델의 최대 컨텍스트 크기 설정\n",
    "context_size = model.pos_emb.weight.shape[0] \n",
    "\n",
    "for i in range(10):  # 10개의 시퀀스를 생성\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=idx.to(device),  # 입력 토큰을 GPU/CPU로 이동\n",
    "        max_new_tokens=50,  # 최대 50개 토큰 생성\n",
    "        context_size=context_size,  # 컨텍스트 크기 설정\n",
    "        top_k=50,  # 확률이 높은 50개 단어 중 샘플링\n",
    "        temperature=0.5  # 확률 분포 조정 (낮을수록 보수적인 선택)\n",
    "    )\n",
    "\n",
    "    flat = token_ids.squeeze(0)  # 배치 차원 제거\n",
    "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")  # 텍스트 변환 후 줄바꿈 제거\n",
    "\n",
    "    print(i, \":\", out)  # 생성된 텍스트 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supernova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
